{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d2e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82816994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T03:36:01.081741Z",
     "start_time": "2022-05-13T03:36:00.106768Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "import random\n",
    "import gc\n",
    "from itertools import chain\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms as transforms\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0506bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T03:36:02.588557Z",
     "start_time": "2022-05-13T03:36:02.511056Z"
    }
   },
   "outputs": [],
   "source": [
    "# user modules\n",
    "sys.path.append(path.dirname(path.abspath('')))\n",
    "from models.wideresnet import WideResNet\n",
    "from models.resnet import ResNet9, ResNet50\n",
    "import metrics.similarity as sim\n",
    "from data.partition import partition_data, get_partition_dict\n",
    "from data.datasets import load_cifar10_data\n",
    "from data.dataloader import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8102c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T03:36:03.018234Z",
     "start_time": "2022-05-13T03:36:03.004514Z"
    }
   },
   "outputs": [],
   "source": [
    "from losses import SRIPLoss, OCNNLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f29ed10d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T03:36:03.431551Z",
     "start_time": "2022-05-13T03:36:03.428783Z"
    }
   },
   "outputs": [],
   "source": [
    "l = SRIPLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c92ebdba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T03:38:46.368242Z",
     "start_time": "2022-05-13T03:38:46.121671Z"
    }
   },
   "outputs": [],
   "source": [
    "t1 = torch.rand(1, 10)\n",
    "t2 = torch.randint(low=0, high=10, size=(1,))\n",
    "model=WideResNet(28, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6ebd3c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-13T03:38:47.382088Z",
     "start_time": "2022-05-13T03:38:47.242629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"Tensor\") to tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch182/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/mnt/c/Users/ajh50/workspace/Fed-Framework/losses.py:50\u001b[0m, in \u001b[0;36mSRIPLoss.forward\u001b[0;34m(self, input, target, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m celoss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[1;32m     49\u001b[0m oloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2_reg_ortho(model)\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mceloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moloss\u001b[49m, oloss\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"Tensor\") to tuple"
     ]
    }
   ],
   "source": [
    "l(t1, t2, model=model, decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaac0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9c35863a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:04:54.036497Z",
     "start_time": "2022-05-11T07:04:54.029536Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3b4da2f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:04:54.042255Z",
     "start_time": "2022-05-11T07:04:54.037832Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_ckpt(expname, comm, modeldir='../ckpt', epoch=None, client=None):\n",
    "    f = filter(lambda x: expname in x, os.listdir(modeldir))\n",
    "    f = filter(lambda x: f'comm{comm:03}' in x, f)\n",
    "    if client is None:\n",
    "        f = filter(lambda x: f'GLOBAL' in x, f)\n",
    "    else:\n",
    "        if epoch:\n",
    "            f = filter(lambda x: f'epoch{epoch:03}' in x, f)\n",
    "        f = filter(lambda x: f'CLIENT{client:02}' in x, f)\n",
    "    return list(f)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "22bdbe00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:04:54.047840Z",
     "start_time": "2022-05-11T07:04:54.043164Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_repr(model, dataset, layers, n_samples, device):\n",
    "    reprs = []\n",
    "#     def pre_hook(module, input_):\n",
    "#         reprs.append(input_)\n",
    "    def hook(module, input_, output):\n",
    "#         print(f'hook executed in {module}')\n",
    "        reprs.append(output)\n",
    "    if layers is not None:\n",
    "        modules = [v for k, v in model.named_modules() if k in layers]\n",
    "    else:\n",
    "        modules = [v for k, v in model.named_modules()]\n",
    "#     print(f'Registered hook for {len(modules)} modules.')\n",
    "    for module in modules:\n",
    "        module.register_forward_hook(hook)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ds = [data for data, target in dataset]\n",
    "#         random.shuffle(ds)\n",
    "        data = torch.stack(ds[:n_samples])\n",
    "        if device:\n",
    "            model = model.to(device)\n",
    "            data = data.to(device)\n",
    "        model(data)\n",
    "#     return [rep.view(rep.shape[0], -1).to(device) for rep in reprs]\n",
    "    return [rep.to(device) for rep in reprs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "69a4913f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:04:54.054606Z",
     "start_time": "2022-05-11T07:04:54.048759Z"
    }
   },
   "outputs": [],
   "source": [
    "def channelwise_CKA(X, Y=None, device=None):\n",
    "    size = len(X)\n",
    "    mat = np.zeros((size, size))\n",
    "    if Y is None:\n",
    "        Y=X\n",
    "    X=X.to(device)\n",
    "    Y=Y.to(device)\n",
    "    for i in tqdm(range(size)):\n",
    "        for j in range(size):\n",
    "            mat[i][j] = sim.kernel_CKA(X[i].view(len(X[i]), -1), Y[j].view(len(Y[i]), -1), device=device)\n",
    "    return mat\n",
    "\n",
    "def clientwise_CKA(cl_a, cl_b, n_samples=256, device=None):\n",
    "    size = len(X)\n",
    "    mat = np.zeros((size, size))\n",
    "    if Y is None:\n",
    "        Y=X\n",
    "    for i in tqdm(range(size)):\n",
    "        for j in range(size):\n",
    "            mat[i][j] = sim.kernel_CKA(X[i].view(len(X[i]), -1), Y[j].view(len(Y[i]), -1), device=device)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7c3ed263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:04:54.060057Z",
     "start_time": "2022-05-11T07:04:54.055618Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_sim(model_a, model_b,  dataset_a, dataset_b=None, layers_a=None, layers_b=None, n_samples=256, device=None):\n",
    "#     assert model_a == model_b\n",
    "#     assert dataset_a == dataset_b\n",
    "#     assert layers_a == layers_b\n",
    "    dataset_b = dataset_b or dataset_a\n",
    "    reprs_a= extract_repr(model_a, dataset_a, layers_a, n_samples, device=device)\n",
    "    reprs_b= extract_repr(model_b, dataset_b, layers_b, n_samples, device=device)\n",
    "    cka = np.zeros((len(reprs_a), len(reprs_b)))\n",
    "    i=0\n",
    "    for r_a in tqdm(reprs_a):\n",
    "        j=0\n",
    "        for r_b in reprs_b:\n",
    "            with torch.no_grad():\n",
    "                cka[i,j] = kernel_CKA(r_a, r_b, device=device)\n",
    "            j+=1\n",
    "        i+=1\n",
    "    return cka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c1c3cb65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:04:54.066552Z",
     "start_time": "2022-05-11T07:04:54.060821Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot(sim, path):\n",
    "    plt.figure(figsize=(30, 15), dpi=200)\n",
    "    axes = plt.imshow(sim, cmap='magma', vmin=0.0,vmax=1.0)\n",
    "    axes.axes.invert_yaxis()\n",
    "    if path:\n",
    "        plt.savefig(path, dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7ca0f0cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:04:54.072887Z",
     "start_time": "2022-05-11T07:04:54.067598Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "cnum_a, cnum_b: -1 means global\n",
    "dsetnum_a, dsetnum_b: -1 means testset\n",
    "'''\n",
    "def compare_model(\n",
    "    cnum_a, cnum_b, dsetnum_a, dsetnum_b,\n",
    "    comm_round, partition, expname,\n",
    "    datadir='~/data', modeldir='../ckpt',\n",
    "    model=None,\n",
    "    num_classes=10,\n",
    "    epoch=None,\n",
    "    device=torch.device('cuda')\n",
    "):\n",
    "    # load dataset index map\n",
    "    target_idx = dsetnum_a\n",
    "    if dsetnum_a<0:\n",
    "        target_idx = 0\n",
    "    net_dataidx_map = get_partition_dict('cifar10', partition, 10, datadir='~/data', init_seed=0)\n",
    "    _, _, trainset, testset= get_dataloader(\n",
    "        'cifar10', '~/data', 256, 32,\n",
    "        net_dataidx_map[target_idx], 0, augment=False\n",
    "    )\n",
    "    dset_a = testset if dsetnum_a<0 else trainset\n",
    "        \n",
    "    if dsetnum_a == dsetnum_b:\n",
    "        dset_b = dset_a\n",
    "    elif dsetnum_b<0:\n",
    "        dset_b = testset\n",
    "    else:\n",
    "        _, _, trainset, testset= get_dataloader(\n",
    "            'cifar10', '~/data', 256, 32,\n",
    "            net_dataidx_map[dsetnum_b], 0, augment=False\n",
    "        )\n",
    "        dset_b = trainset\n",
    "\n",
    "    # model to compare\n",
    "    net_a = model(num_classes=num_classes)\n",
    "    net_a.load_state_dict(torch.load(\n",
    "        os.path.join(modeldir, find_ckpt(expname, comm=comm_round, client=cnum_a if cnum_a>=0 else None, modeldir=modeldir, epoch=epoch))\n",
    "    ))\n",
    "    if cnum_a == cnum_b:\n",
    "        net_b = net_a\n",
    "    else:\n",
    "        net_b= model(num_classes=num_classes)\n",
    "        net_b.load_state_dict(torch.load(\n",
    "            os.path.join(modeldir, find_ckpt(expname, comm=comm_round, client=cnum_b if cnum_b>=0 else None, modeldir=modeldir, epoch=epoch))\n",
    "        ))\n",
    "        \n",
    "    cond = lambda x: 'activation' in x\n",
    "#     cond = lambda x: ('conv' in x) or ('batchnorm' in x) or ('activation' in x)\n",
    "    layers_a = [k for k, v in net_a.named_modules() if cond(v.__module__)]\n",
    "    layers_b = [k for k, v in net_b.named_modules() if cond(v.__module__)]\n",
    "    \n",
    "    try:\n",
    "        cka = calc_sim(\n",
    "            net_a, net_b, dataset_a=dset_a, dataset_b=dset_b, layers_a=layers_a, layers_b=layers_b, device=device\n",
    "        )\n",
    "    finally:\n",
    "        del net_a, net_b, dset_a, dset_b\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    return cka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "af686074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:04:55.873625Z",
     "start_time": "2022-05-11T07:04:54.074317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset PreP\n",
    "net_dataidx_map = get_partition_dict('cifar10', 'homo', 10, datadir='~/data', init_seed=0)\n",
    "_, _, trainset, testset= get_dataloader(\n",
    "    'cifar10', '~/data', 256, 32,\n",
    "    net_dataidx_map[0], 0, augment=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9520e7fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:04:56.016886Z",
     "start_time": "2022-05-11T07:04:55.874727Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "dummyset = copy(testset)\n",
    "dummyset.data = (np.random.rand(*testset.data.shape)*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cfb7dc40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:04:56.022606Z",
     "start_time": "2022-05-11T07:04:56.018235Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_ce_orth(cl_num, layeridx, comm, dataset, samples=256):\n",
    "    ckpt = find_ckpt('WRN-28-10-CE', comm=comm, client=cl_num)\n",
    "    # load model\n",
    "    model=WideResNet(28, 10, 10)\n",
    "    model.load_state_dict(torch.load(f'../ckpt/{ckpt}'))\n",
    "\n",
    "    # Select layer\n",
    "    cond = lambda x: 'activation' in x\n",
    "    layers = [k for k, v in model.named_modules() if cond(v.__module__)]\n",
    "    layer = layers[layeridx]\n",
    "    print(layer)\n",
    "\n",
    "    # extract repr\n",
    "    rep_ce = extract_repr(model, dataset, [layer], samples, 'cuda')\n",
    "\n",
    "    # model 2\n",
    "    ckpt = find_ckpt('WRN-28-10-ORTH', comm=comm, client=cl_num)\n",
    "    model.load_state_dict(torch.load(f'../ckpt/{ckpt}'))\n",
    "    rep_orth = extract_repr(model, dataset, [layer], samples, 'cuda')\n",
    "\n",
    "    a = channelwise_CKA(\n",
    "        rep_ce[0].swapaxes(0,1),\n",
    "        rep_ce[0].swapaxes(0,1),\n",
    "        'cuda'\n",
    "    )\n",
    "    b = channelwise_CKA(\n",
    "        rep_orth[0].swapaxes(0,1),\n",
    "        rep_orth[0].swapaxes(0,1),\n",
    "        'cuda'\n",
    "    )\n",
    "\n",
    "    # client 0, 'block1.layer.0.relu2', channelwise\n",
    "    print('Mean cka(except self)')\n",
    "    print(f'A: {(np.sum(a)-a.shape[0])/(a.size-a.shape[0]):.2f}')\n",
    "    print(f'B: {(np.sum(b)-b.shape[0])/(b.size-b.shape[0]):.2f}')\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20,15))\n",
    "    sns.heatmap(a, ax=axes[0][0])\n",
    "    sns.heatmap(b, ax=axes[0][1])\n",
    "    sns.histplot(a.flatten(), ax=axes[1][0])\n",
    "    sns.histplot(b.flatten(), ax=axes[1][1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cffa160e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:05:02.617538Z",
     "start_time": "2022-05-11T07:04:56.023561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1.layer.0.relu2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [143]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompare_ce_orth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcl_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayeridx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [142]\u001b[0m, in \u001b[0;36mcompare_ce_orth\u001b[0;34m(cl_num, layeridx, comm, dataset, samples)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# model 2\u001b[39;00m\n\u001b[1;32m     17\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m find_ckpt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWRN-28-10-ORTH\u001b[39m\u001b[38;5;124m'\u001b[39m, comm\u001b[38;5;241m=\u001b[39mcomm, client\u001b[38;5;241m=\u001b[39mcl_num)\n\u001b[0;32m---> 18\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../ckpt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mckpt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     19\u001b[0m rep_orth \u001b[38;5;241m=\u001b[39m extract_repr(model, dataset, [layer], samples, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m a \u001b[38;5;241m=\u001b[39m channelwise_CKA(\n\u001b[1;32m     22\u001b[0m     rep_ce[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     23\u001b[0m     rep_ce[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     25\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch182/lib/python3.9/site-packages/torch/serialization.py:592\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    590\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[1;32m    591\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 592\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch182/lib/python3.9/site-packages/torch/serialization.py:851\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    849\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mUnpickler(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m    850\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m--> 851\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/torch182/lib/python3.9/site-packages/torch/serialization.py:843\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    841\u001b[0m data_type, key, location, size \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[0;32m--> 843\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m storage \u001b[38;5;241m=\u001b[39m loaded_storages[key]\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m storage\n",
      "File \u001b[0;32m~/anaconda3/envs/torch182/lib/python3.9/site-packages/torch/serialization.py:831\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    828\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    829\u001b[0m dtype \u001b[38;5;241m=\u001b[39m data_type(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m--> 831\u001b[0m storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstorage()\n\u001b[1;32m    832\u001b[0m loaded_storages[key] \u001b[38;5;241m=\u001b[39m restore_location(storage, location)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compare_ce_orth(cl_num=0, layeridx=1, comm=10, dataset=testset, samples=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e45415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:05:02.619572Z",
     "start_time": "2022-05-11T07:05:02.619565Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_ce_orth(cl_num=0, layeridx=1, comm=20, dataset=testset, samples=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b191361b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:05:02.620072Z",
     "start_time": "2022-05-11T07:05:02.620065Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_ce_orth(cl_num=0, layeridx=1, comm=40, dataset=testset, samples=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22650717",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:05:02.620792Z",
     "start_time": "2022-05-11T07:05:02.620785Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_ce_orth(cl_num=0, layeridx=2, comm=50, dataset=testset, samples=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a881b39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:05:02.621342Z",
     "start_time": "2022-05-11T07:05:02.621336Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_ce_orth(cl_num=0, layeridx=-1, comm=50, dataset=testset, samples=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417f9a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:05:02.621981Z",
     "start_time": "2022-05-11T07:05:02.621975Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_ce_orth(cl_num=0, layeridx=-10, comm=50, dataset=testset, samples=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e5cdd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:05:02.622698Z",
     "start_time": "2022-05-11T07:05:02.622691Z"
    }
   },
   "outputs": [],
   "source": [
    "compare_ce_orth(cl_num=0, layeridx=7, comm=50, dataset=testset, samples=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ad5694a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:05:29.193150Z",
     "start_time": "2022-05-11T07:05:28.854958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1.layer.3.relu2\n"
     ]
    }
   ],
   "source": [
    "model=WideResNet(28, 10, 10)\n",
    "cond = lambda x: 'activation' in x\n",
    "layers = [k for k, v in model.named_modules() if cond(v.__module__)]\n",
    "layer = layers[7]\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3e90b8c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:05:35.819203Z",
     "start_time": "2022-05-11T07:05:35.813669Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, resnet34, resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "86ae50ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:05:36.755510Z",
     "start_time": "2022-05-11T07:05:36.226996Z"
    }
   },
   "outputs": [],
   "source": [
    "r18 = resnet18()\n",
    "r34 = resnet34()\n",
    "r50 = resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3c2f3126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:14:50.307223Z",
     "start_time": "2022-05-11T07:14:50.303736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_children of WideResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (block1): NetworkBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (convShortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block2): NetworkBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (convShortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block3): NetworkBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (convShortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (fc): Linear(in_features=640, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059653f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.utils import A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7c922a24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:14:02.728299Z",
     "start_time": "2022-05-11T07:14:02.721027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r18.layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b9ae5493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:17:52.260935Z",
     "start_time": "2022-05-11T07:17:52.255202Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v for k, v in list(r18.named_modules()) if 'conv1' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41eb668",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:05:02.626669Z",
     "start_time": "2022-05-11T07:05:02.626662Z"
    }
   },
   "outputs": [],
   "source": [
    "[v for k, v in list(model.named_modules()) if v.__dict__.get('kernel_size') == (1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227663b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:05:02.627065Z",
     "start_time": "2022-05-11T07:05:02.627058Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt = find_ckpt('WRN-28-10-CE', comm=comm, client=cl_num)\n",
    "# load model\n",
    "model=WideResNet(28, 10, 10)\n",
    "model.load_state_dict(torch.load(f'../ckpt/{ckpt}'))\n",
    "\n",
    "# Select layer\n",
    "cond = lambda x: 'activation' in x\n",
    "layers = [k for k, v in model.named_modules() if cond(v.__module__)]\n",
    "layer = layers[layeridx]\n",
    "print(layer)\n",
    "\n",
    "# extract repr\n",
    "rep_ce = extract_repr(model, dataset, [layer], samples, 'cuda')\n",
    "\n",
    "# model 2\n",
    "ckpt = find_ckpt('WRN-28-10-ORTH', comm=comm, client=cl_num)\n",
    "model.load_state_dict(torch.load(f'../ckpt/{ckpt}'))\n",
    "rep_orth = extract_repr(model, dataset, [layer], samples, 'cuda')\n",
    "\n",
    "a = channelwise_CKA(\n",
    "    rep_ce[0].swapaxes(0,1),\n",
    "    rep_ce[0].swapaxes(0,1),\n",
    "    'cuda'\n",
    ")\n",
    "b = channelwise_CKA(\n",
    "    rep_orth[0].swapaxes(0,1),\n",
    "    rep_orth[0].swapaxes(0,1),\n",
    "    'cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7412c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "torch182",
   "language": "python",
   "name": "torch182"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
